“If I were not a physicist, I would probably be a musician. I often think in
music. I live my daydreams in music. I see my life in terms of music.” ― Albert
Einstein

Hey New Merchants. Welcome to the first video in a series on the essentials of
music. I'm creating this series with scientists and engineers in mind,
but foremost the musician in you... whether you're just picking up a musical
instrument or already have ten thousand hours; there should be something in store
for you.

Now, my objective with this series is to empower you to discover and create
music by offering both a conceptual and practical understanding of its
fundamentals; however, since music encompasses an endless variety of sounds with
different cultures around the world producing their own genres,
there's a lot of ground I couldn't possibly cover... so here's a what I have in
mind for this series:

Typically musicians are told to simply practice and commit certain musical ideas
to muscle memory. Ideas like rhythm and time signatures; scales and keys;
musical circles and chords, among others things...  and my goal is for you walk
away from this series feeling like you could have created much of the music that
exists today.

In this first video, we'll seek a holistic understanding of sound and pull
from a wide range of topics including physics, biology, and math. If you're not
particularly fond of a subject, skip around! You can certainly make music
without knowing all of the science and math and maybe the second video will be
more for you.

I am a firm believer in mind and hand, or in learning by doing. This series is
largely meant to supplement your practice, the expectation being that a few
hours with this knowledge and your instrument will be more meaningful than many
hours without it.

Without further ado, let's introduce the defining characteristic of music:
sound. But what is sound?

############### Human physiology/perception of sound: ###############
### What is sound?

Sound is a vibration that travels as a wave through matter like solids, liquids,
and gasses, but typically the medium is air. Notice how the particles in yellow
oscillate back and forth in space to form high and low pressure spots. These
regions of compression and rarefactions aid the propagation of the wave but the
particles themselves are not traveling with the wave.

If we increase the wave's amplitude, the particles cover more distance in the
same amount of time and must move more quickly, but the wave still travels the
same speed.

If we hold the wave speed constant and increase the wave's frequency, the
wavelength shortens as the particles move even faster in order to finish their
round trips more frequently.

But what produces these vibrations?
### What makes sound?

Well if you're currently listening in on this video, chances are your dynamic loudspeaker.

This variant of loudspeaker has a voice coil attached to a diaphragm and a
permanent magnet at its base and to figure out how this produces sound, we have 
19th century scientist, James Maxwell, who published a set of four elegant
equations, Maxwell's equations, that describe much of classical
electromagnetism. The details of the equations I'll leave to your high school
and college physics courses, or perhaps a future series, but the last two are of
utmost importance to us and describe a beautiful dance. The Maxwell-Faraday
equation on top describes how time-varying magnetic fields generate electric
fields, and implicitly electrical currents, whiles Ampere's Law with Maxwell's
addition, the bottom equation, describes how electrical currents and
time-varying electric fields produce magnetic fields. 

In practice this means a conductive ring moving around a magnet generates a
current as indicated by the small moving spheres in the ring. This current then
produces a magnetic field that opposes the magnet's and pull it back towards the
magnet. If the ring the ring passes by the magnet, the current changes direction
in attempts to oppose the magnet's field. The magnetic flux wants to stay
constant.

In the case of a solenoid where there is no magnet, a current by itself produces
a magnetic field.

It is from these principles that the electrical signals sent through the voice
coil moves it, and thus the diaphragm, up and down against the permanent magnet.

This conversion of one form of energy or signal into another is called transduction and
electroacoustic tranducers like your loudspeaker carry out these conversions
between electrical signal, magnetic fields, motion of the diaphragm, and
finally air pressure waves... or in the case of my microphone, the same steps
as the speaker but in reverse.

Now loudspeakers are incredibly inefficient and convert only .5 to 2 percent of
their energy into acoustical waves! You actually have more efficient transducers
on your person and they're called ears.

### How do we hear sound?

Ultimately our perception of sound is the vibration of the stereocilia in our inner
ears... but let's back up a bit:

As the waves reach the outer ear, the pinna funnels the sound into the ear
canal to the tympanic membrane, or ear drum. Pressure differences as low as 20
micro Pa, the threshold of hearing, move the ear drum enough to be audible, but
when the pressure exceeds the threshold of pain at 20 Pa hearing loss can occur.

On the other side of the ear drum is the middle ear. The eustachian tube
equalizes the pressure with the outer ear so the ear drum can efficiently move.
When you swallow, or plug your nose and blow, you're opening your eustachian
tube.
Attached to the ear drum is the malleus which connects in series to the incus,
and finally the smallest bone in the body, the stapes. These bones transfer
sound mechanically to the inner ear. If the incoming sound is too loud, a muscle
will react and dampen the sound but since the muscle can fatigue and is
sometimes too slow to react it's best to us hearing protection in loud places.

The inner ear is the last stop before the brain processes sound signal sent to
the cochlear nerve. The snail-looking cochlea is a fluid-filled tube which
connects to the cochlear nerve. The stapes from the middle ear connects to the
oval window at one end of the tube which coils up the snail to a narrow
passageway called the helicotrema before doubling back to the round window. When
the stapes vibrates the oval window, the round window moves in a complementary
fashion. The human range of hearing is around 20,000 Hz towards the start of the
oval window and 20 Hz towards the helicotrema. 

Along the length of the cochlea, down the center of the tube, are roughly 30,000
hair cells with stereocilia which sit in a fluid filled with cations. They sit
on top of the thin basilar membrane and span a small gap to connect to the
tectorial membrane. When the fluid of the cochlea vibrates from the
stapes, the basilar membrane moves and the hair cells are sheared against the
tectorial membrane allowing cations to enter the hair cells and trigger a
neurological response which is sent to the brain.

We are, albeit with many steps of transduction, bridging our minds
digitally.  From my mind to yours, to the neurological impulses sounded by my
vocal cords and heard by your ears, to the signal received by my microphone and
played by your speakers, and finally the analog-digital and digital-analog
conversions for this video; I find it both bewildering and awe inspring that
we're watching this at all. 

################ The physics and properties of sound as it relates to hearing audio: ###############
### What is sound's geometric qualities?

Now that we've established some of the core ideas to our perception of sound,
let's investigate their geometrical properties.

Because sound waves are cyclical, we turn to the circle which is also cyclical
to understand them. We'll be working with angles theta in radians which are a
dimensionless unit. One radian is where the radius of the circle equals the
distance traveled along the circumference of the circle.  After traveling PI
radians around the circle, we're halfway around, and after TAU radians, or 2
steps of PI radians, we've come full circle.

Two extremely important relations to the circle are the trigonometry functions,
cosine and sine. Given an angle theta of PI halves radians, we sit at the top of
the circle of radius one, cos describes our x coordinate and sin describes the y
coordinate on a unit circle, but for any other circle, we have to multiply
these functions by the radius, r. Intuitively, sin is positive on the top half of
the circle and negative on the bottom half. Cos is negative on the left side,
and positive on the right side. After completing a round trip, the values of
cosine and sine on the right are the same as the values on the left. For any
full rotation of TAU radians, it's as if we never left.

Cosine and sine are very similar to eachother. With greek letter phi, we can
phase shift the graph of sin. If we shift by PI halves radians, we can see that
cosine and sin behave the same.

When we start to factor in the time it takes to travel around the circle, just
like we have velocities for cars which describe how fast and which direction, we
also have angular velocity which describes how fast and which direction around
the circle. Given by the orange greek letter omega, we define it as theta
radians around the circle in t seconds. Given any two of the three variables, an
angular velocity, a angle traveled, or the time elasped, we can figure out the
third.

We're typically concerned with how many seconds it takes to make a trip of TAU
radians as this describes the time period that it takes for once full cycle,
indicated by a capital T. Inverting this time period, we get a frequency of full
revolutions made each second.

Despite time moving forward, each round trip is as if we never moved.

These sinusoidal curves have some additional geomtrical properties. The
amplitude adjust the radius of the unit cirle, and it's related to how loud the
sound wave is. Moving from angle theta to distance x. The wavelength, given by
the pink, greek letter lambda, describes the distance until a full revolution of
the circle. Currently the wavelength is 2 PI, but to make the math simpler we'll
omit the factor of 2 PI and use the wavenumber given by greek letter kappa. This
describes how many revolutions occur in normal span of 2 PI. The lower the
wavenumber the longer the wavelength. The higher the wavenumber, the shorter the
wavelength.

Since theta is equal to omega times time, we can introduce time as a parameter
of the function. I write the plus/minus sign here since time can only move
forward, but waves move both forwards and backwards. These are two separate
equations where the minus sign variant indicates forward wave propogation, and
taking the positive sign means backwards wave propogation. We'll use the forward
propogation wave with these upcoming animations though. At an omega of 1, it
takes a period of TAU seconds to make one revolution. To speed the period up,
we increase omega to TAU radians per second and now the wave makes the trip in
one second.

You may have noticed the wave moved much quicker. The speed of the wave is
proportional to the wavelength, and inversely proportional to the period so
anything we can do to increase the wavelength, or decrease the period will speed
up the wave. Doing some algebra using our frequency and wavenumber relation, we
can that kappa and omega both affect the wavespeed. That makes sense,
they're both inside the trig function affecting our space and time variables.

As a brief aside, we can actually speed up the wave so that it appears not to
move. Since this video was rendered at sixty frames per second, a wave speed of
sixty * TAU units per second makes the yellow dot moves one full wave length
between frames. If we slow the wave down just a bit, it appears to be moving
backwards but it's actually moving extremely fast forward. If we speed it up
just a bit, it'll appear to move forward slowly. This is a form of aliasing and
in a future video we'll talk more in-depth about it, but anyways...

We add in the phase shift term from earlier to account for any intial offsets of the
wave and now we're describing two solutions to a very important PDE called the
wave equation.

To derive it, we'll use a bit of calculus and our intuition that space and time
are somehow related because they both exhibit a cyclical behavior of having zero
displacements at certain wavelength distances and time periods.

Taking partial derivatives, one with respect to space and the other with time,
tells us the input variable's affect on the wave displacement. We
use the fact that cosine's derivative is negative sine and the chain rule whiles
treating the other variable as a constant to arrive at these two first order
partial derivatives. Space's story describes the slope of the wave and time's
story describes the velocity of the particles.

Taking a second partial derivative of space and time, we use the fact that the
derivative of sine is cosine and the chain rule while treating the other input
variable constant.
The second partial derivative w.r.t space describing the how the slope changes,
or its concavity and the second partial derivative w.r.t time describes the
acceleration of the particle.

The two of these 2nd order partial derivatives are nearly identical, differing
only by factors of kappa squared and omega squared. If you'll recall from
earlier that the wave speed is related to omega over kappa, we can rewrite this
in it's final form which states: the 2nd partial derivative w.r.t space times
the speed of the wave squared is equal to the 2nd partial derivative w.r.t time.

This equation is incredibly short and sweet yet it describes so much about sound 
and other wave phenomenon.
Despite sticking to waves traveling in a single dimension this video, the wave 
equation does provide insights into 2D and 3D waves like those you might
experience with water, seismic, and light waves.

Conclusion:
Before signing off, I want to pay tribute to Gareth Loy who wrote two volumes to
a series titled Musimathics that I truly believe youd enjoy. This isn't a
sponsored message, I just really think you'd like the book especially if you're
interested in the intersection of music and math. It was a great resource as a
student and continues to be a resource as a musician, engineer, and even now in
this video.
https://amzn.to/37UATbm vol 1
https://amzn.to/3suFv1u vol 2

Hopefully you now have a deeper understanding of the fundamental building block
of music. In the coming videos, we'll discuss the finer details about sound
manipulation and more complicated wave shapes.

If you made it this far, consider liking, subscribing, and even sharing the
video with others. Til' next time, thanks for watching.

# Sections I didn't get to, for future?

## digital/analog stuff

In much the same way that our stereocilia vibrate due to pressure waves, a
condenser microphone's (also called a capacitor microphone) diaphram also
vibrates due to pressure waves (note there many types of microphones that
function a bit differently). The diaphragm in a microphone acts as one of the
two plates of a capacitor and stores a relatively constant electric charge; when
vibrations move the diaphragm, the distance between the diaphragm and other
plate in the capacitor changes which ultimately results in changes to
capacitance and voltage in the circuit.

From the laws surrounding electromagnetism, this displacement of charge in an
electric field acts as an instantaneous change in voltage with closer distances
equating to negative voltage change, and further distances being more positive.
It is this voltage which changes with time that we are measuring when recording
audio signals. When we talk about other electrical instruments, the voltage is
ultimately still being measured with time, but sometimes in a
different manner. For instance, an electric bass doesn't use a diaphragm and
capacitance to measure voltage; but instead relies on magnetism and
inductance to generate alternating current. This current relates to voltage
through Ohm's law, where a majority of the resitance comes from the variable
resistance in the potentiometer, or volume knob. As the volume knob is turned
up, so too does the voltage in the circuit; and as the amplitude of the string
vibration increase with stronger strums, the current increases as with the
voltage. This allows us to consistently use voltages to represent audio signal
which is helpful when storing the signal's information for playback.

The voltage information present in audio signals can be sent to other analog
devices, or converted to a digital representation of the signal through an
audio interface. In contrast to analog signals, digital signals do not retain
as much of the information within an audio signal as they sample voltages from
the continous version of the signal at a set rate. The faster the sampling rate
of the signal, the more accurate the digital copy can represent its analog
counterpart, but it isn't all sampling rate. The bit depth is the quality of
information stored at each sample; with low bit depth, the digital signal
produces a noisy copy of the analog signal and with higher bit depths the noise
added to signal decreases. The true signal may be best represented when it is
visualized directly from the source, but as soon as we attempt to store this
information with analog physical copies like: vinyl discs, or even digital
copies like: WAV or MP3 files, we lose definition in the audio source. One
might imagine that like biological cells performing mitosis over a lifetime and
undergoing mutations that eventually lead to nonfunctional cells, or
photocopying an original document again and again until it's no longer
readable; so too does constant resampling and conversion of an audio signal
result in indiscernible noise.

On the subject of sampling, isn't a wonder why we've established a minimum
sampling rate of 44.1 kHz? It is worth briefly mentioning that human hearing is
only capable of hearing frequencies between roughly 20Hz and 20000Hz. If we
undersampled the audio signal, we would experience aliasing -----------
Talk about nyquist rate

# Revisit next chapter

Sound propogates through all states of matter in two specific types of wave forms:
Longitudinal waves and transverse waves (put up animations next to eachother)
In longitudinal, or compression waves, sound may be transferred through all
states of matter and is best described as waves formed by regions of compression
and rarefaction.
(solo diagram pointing out the regions of compression and rarefaction in 2D -- and 3D case if possible).
Transverse waves on the other hand are only possible in solid mediums and are
described as waves of alternating shear forces.
(solo diagram pointout out the shear forces in 2D -- and 3D if possible)

Sound waves, as with electromagnetic waves like light, can be reflected,
refracted, or attenuated by the medium. Just as a varying wavelengths of light
can reflect off a mirror, change angle when going in and out of different
mediums, or be absorbed in solar panels; sound can bounce off of hard surfaces
producing echoes, change direction as it propogates through air and then water,
or be dampened as the sounds energy is absorbed. The attenuation in many media,
such as water and air, is negligible; but is still an interesting phenomenon
nonetheless depending on the viscocity of the medium.

Also relevant to sound and electromagnetic waves are that they travel with varying speed. In
electromagnetic waves, the speed limit is a universal limit, which follows as a
consequence of Einstein's theory of relativity. Nothing with matter can travel
faster than the speed of light in a vaccuum... but as the medium that light
travels through changes, so does the speed of light. The speed of sound is no
different in that the properties of the medium it travels through determine its
speed since the propogation of sound ultimately boils down to atoms bouncing
into each other and produce this wave effect; but it's quite opposite from
electromagnetic waves.
The biggest difference is that light is fastest in a vacuum whereas sound is
slowest, or doesn't propogate at all, in a vacuum. The takeaway here, is that
sound requires matter to propagate its waves.

Now there exists a couple of complex relationships governing the speed of sound
in a medium; namely its pressure, density, heat capacity ratio, temperature,
and motion. For the sake of simplicity, we won't deal with general relativity
and sound, but I will leave resources in the description for the more curious
among you. The Newton-Laplace equation (show equation) deals with first four
relationships. It states that the speed of sound in a medium is proportional to
the square root of the heat capacity ratio and pressure whiles inversely
proptional to the square root of its density. Here, the heat capacity is a
measure of how much heat must be supplied to a given mass of a material to
raise its temperature by a unit; and the ratio involves the heat capactiy at
constant pressure divided by the heat capacity at constant volume. With the
ideal gas law, the assumption is that this ratio doesn't change; however, in a
real gas, both heat capacities increase and continue to differ from each other
by a fixed constant. This fixed difference results in a ratio that decreases
with increasing temperatures.

In the case of a moving medium, the speed of sound changes depending on the
direction of speed, or velocity, relative to a listener. In the case of a tweeting bird
flying in the wind, it's apparent velocity relative to a stationary
listener is the speed of sound as calculated with the Newton-Laplace equation,
in addition to the velocity of the bird and velocity of the wind. (Give animation of a few sample cases)

The speed of a sound is a very important trait when dealing with nuances like
tuning all of the instruments in a band after traveling to a different
elevation above sea-level, listening to a siren coming down a street, or the
classic comedic example of inhaling gasses of varying densities from balloons.

When someone inhales inert gasses like helium, or sulphur-hexafluoride, the
density term in the Newton-Laplace equation changes. If the density is less
than air, as is the case with helium, the speed of sound increases; conversely,
SF6 is more dense than air and slows the speed of sound. The affect on the
listener are interesting changes to the quality of the sound produced. Let's
breakdown the case of inhaling helium and discover why it changes the quality
of sound. Since we've established that the sound waves in the vocal tract
filled with helium is faster than a vocal tract filled with air, and we've also
established that speed of a plane wave is proportional to its frequency and
wavelength, we can conclude that either the frequency, or wavelength, of the
wave changed in order for the speed of sound to have increased. The fundamental
wavelength of the sound depends only on the shape of the vocal tract, and thus
we can reason that the frequency of the sound wave increased. Note, it is
important to distinguish that what's changed here is not the rate at which the
vocal cords are vibrating, but rather the resonant frequency of the vocal
tract. Take a minute to try and reason about gasses with lower densities like
sulfur-hexafluoride producing lower resonant frequencies.

Beyond the physical properties of sound lay the characteristics, or
qualities, that allow listeners to distinguish a variety of sounds. These
include the pitch, timbre, duration, dynamics, texture, and spatial location of
a sound. When dealing with:
########### Characteristics/qualities of sound: ########################################
Pitch:

Pitch, or the fundamental frequency, this stems directly from the vibrating source
of a sound wave. For instance, a string oscillating at a frequency of
110 Hz (times per second) has a fundamental pitch of 110 Hz, just as a vocal
tract, oboe, or bongo, vibrating at 110 Hz also has a fundamental pitch of
110Hz. The key factor that allows a trained listener to differentiate between
the instrument is called its timbre.

Timbre/ADSR:
In the previous example with the balloons, the primary characteristic of sound
that changed was the resonant frequencies of the vocal tract producing the
sound and not the fundamental pitch of the vocal tract itself. This quality is
known in a musical context as timbre, color, or tone, and deals with the varying
degree to which natural harmonics of the instrument are heard. Natural
harmonics are whole number multiples of the fundamental frequency, and the
geometry of the instrument, as well as ambient conditions like the speed of
sound in the vessel creating the sound, define which harmonics are heard the
most. Additionally, the attack, decay, sustain and release of a sound source
help to identify it timbre. For instance, a piano hammer striking a string
produces a distinct attack pattern that is characteristic of a percussive
sound, but short decay and long sustain of amplitude in the wave format allows
listeners to easily differentiate a piano from drum.
(Demonstrate different instruments playing the same fundamental)

Duration:
Duration is the perception of how short, or long, a sound is. Most of the time
this is the time that the sound is first produced to the moment it stops; but
this is not always the case as you might guess that the gaps in my voice are
audible, yet disconnected and do not add up to the full length of audio.

Dynamics:
Dynamics, is simply how quiet, or loud, sound produced by the instrument is
perceived, and is related to the total number of auditory nerve stimulations
from the stereocilia. In short time periods (under 200 ms), a very short sound
can sound softer than a longer sound at when played at the same amplitude,
though this effect is not apparent at longer time intervals. Also in line with
this human illusion, is that the complexity of the audio signal triggers more
nerver stimulation resulting the perception of louder sounds. Compare this
simple sine wave to a saw-tooth wave at the same wave amplitude.


Texture/Spatial location:
When dealing with sonic textures, we begin to move on from single instrument
sound sources to many instruments sound sources and focus on the interactions
and differences between the instruments. I use the term instrument loosely
speaking here, as texture can also refer to sounds generated in the environment
that under conventional thought are not considered instruments such as wind,
static, and rain. Within sonic textures, spatial location comes into play once
we begin to think about where the sound source is coming from. The
aformentioned characteristics of sound, such as timbre, can help to place the
sound of an alto saxophone in the orchestra and determine with certainty the
distance from the source as well as its placement vertically and horizontally
from the listener.

Scenes to make:
loudspeaker inefficient